{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XGBoost .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "13xbWtntiQX-"
      },
      "source": [
        "!pip -q install yellowbrick==1.3\n",
        "!pip -q install kneed\n",
        "!pip install fuzzywuzzy\n",
        "!pip install python-Levenshtein\n",
        "!pip install plotly\n",
        "!pip install squarify\n",
        "!pip install chart_studio\n",
        "!pip -q install factor_analyzer\n",
        "! pip install distance\n",
        "!pip install sentence-transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kZPKoRoiawT"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import f_oneway\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.formula.api import ols\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "import datetime\n",
        "import squarify\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONGIl4O5iazF"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWHMwpuJia1H"
      },
      "source": [
        "# download files\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "nlp = gensim_api.load(\"word2vec-google-news-300\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3E13NL1ia28"
      },
      "source": [
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4pxu8PtifKl"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me8cybaNifMg"
      },
      "source": [
        "cleaned_features = pd.read_csv(\"/content/gdrive/MyDrive/CS3244 Machine Learning/Data/cleaned_features.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v75Xc5BnifOb"
      },
      "source": [
        "stopwords_features = pd.read_csv(\"/content/gdrive/MyDrive/CS3244 Machine Learning/Data/stopwords_features.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S6NVmNaii_K"
      },
      "source": [
        "stopwords_lemmatize = pd.read_csv(\"/content/gdrive/MyDrive/CS3244 Machine Learning/Data/stopwords_lemmatize_features.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zViQBBkgijBa"
      },
      "source": [
        "cleaned_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RucT-HthijC7"
      },
      "source": [
        "stopwords_features.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCLY7F-bijE1"
      },
      "source": [
        "stopwords_lemmatize.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6E0ul_KijHJ"
      },
      "source": [
        "cleaned_features_df = cleaned_features.drop(['is_duplicate', 'qid1', 'qid2', 'question1_cleaned', 'question2_cleaned'], axis = 1)\n",
        "f, ax = plt.subplots(figsize=(12, 12))\n",
        "corr = cleaned_features_df.corr()\n",
        "sns.heatmap(corr, annot = True, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf0lOsYsijI_"
      },
      "source": [
        "stopwords_features_df = stopwords_features.drop(['is_duplicate', 'qid1', 'qid2', 'question1_stopwords', 'question2_stopwords'], axis = 1)\n",
        "f, ax = plt.subplots(figsize=(12, 12))\n",
        "corr = stopwords_features_df.corr()\n",
        "sns.heatmap(corr, annot = True, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7BWv0vtioVJ"
      },
      "source": [
        "stopwords_lemmatize_df = stopwords_lemmatize.drop(['is_duplicate', 'qid1', 'qid2', 'question1_stopwords_lemmatize', 'question2_stopwords_lemmatize'], axis = 1)\n",
        "f, ax = plt.subplots(figsize=(12, 12))\n",
        "corr = stopwords_lemmatize_df.corr()\n",
        "sns.heatmap(corr, annot = True, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
        "            square=True, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8cXrmPpioXE"
      },
      "source": [
        "# Building models \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, log_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0I9p9rFip4k"
      },
      "source": [
        "X = cleaned_features.drop([\"is_duplicate\", \"qid1\", \"qid2\", \"question1_cleaned\", \"question2_cleaned\"], axis = 1)\n",
        "y = cleaned_features[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nDjoWR7ip6f"
      },
      "source": [
        "import xgboost as xgb\n",
        "xgb.plot_importance(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dtfy9OGip8W"
      },
      "source": [
        "X = stopwords_features.drop([\"is_duplicate\", \"qid1\", \"qid2\", \"question1_stopwords\", \"question2_stopwords\"], axis = 1)\n",
        "y = stopwords_features[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyisjPa7ip9j"
      },
      "source": [
        "xgb.plot_importance(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMVr7LikivAd"
      },
      "source": [
        "X = stopwords_lemmatize.drop([\"is_duplicate\", \"qid1\", \"qid2\", \"question1_stopwords_lemmatize\", \"question2_stopwords_lemmatize\"], axis = 1)\n",
        "y = stopwords_lemmatize[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39KnWblnivCm"
      },
      "source": [
        "xgb.plot_importance(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPx3fUi6iw2E"
      },
      "source": [
        "X = cleaned_features[[\"cosine_similarity\", \"common_words_count\", \"Partial_Ratio\"]]\n",
        "y = cleaned_features[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5fH3jWuiw3w"
      },
      "source": [
        "X = stopwords_features[[\"cosine_similarity\", \"common_words_count\", \"Partial_Ratio\"]]\n",
        "y = stopwords_features[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr8wfdbSivEv"
      },
      "source": [
        "X = stopwords_lemmatize[[\"cosine_similarity\", \"common_words_count\", \"Partial_Ratio\"]]\n",
        "y = stopwords_lemmatize[[\"is_duplicate\"]]\n",
        "\n",
        "# split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# make predictions for test data\n",
        "y_pred = model.predict(X_test)\n",
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "y_pred2 = model.predict_proba(X_test)\n",
        "ll = log_loss(y_test, y_pred2)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "print('Precision: %f' % precision)\n",
        "print('Recall: %f' % recall)\n",
        "print('F1 Score: %f' % f1)\n",
        "print('AUC-ROC: %f' % roc_auc)\n",
        "print('Log Loss: %f' % ll)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ThVupOyizGC"
      },
      "source": [
        "xgb.plot_importance(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hd88k1-izHt"
      },
      "source": [
        "# Try out 5 fold cross validation here\n",
        "cv = StratifiedKFold(n_splits=5, random_state=13, shuffle=True)\n",
        "fprs, tprs, scores = [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JakdHa-Ai4WE"
      },
      "source": [
        "param_grid = {'subsample': [0.5, 0.6, 0.7, 0.8],\n",
        " 'scale_pos_weight': [1, 2, 3, 4],\n",
        " 'n_estimators': [800, 900, 1000, 1100, 1200],\n",
        " 'min_child_weight': [1, 2, 3],\n",
        " 'max_depth': [10, 11, 12, 13, 14, 15],\n",
        " 'learning_rate': [0.005, 0.01, 0.05, 0.10, 0.15],\n",
        " 'gamma': [4.0, 5.0, 6.0],\n",
        " 'colsample_bytree': [0.6]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1P1En4iMi4YO"
      },
      "source": [
        "#  Create model\n",
        "xg = xgb.XGBClassifier(objective='binary:logistic', silent=True, nthread=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlHHkCFZi6bo"
      },
      "source": [
        "# Instantiate the grid search model\n",
        "grid_search = GridSearchCV(estimator = xg, param_grid = param_grid, \n",
        " cv = 5, n_jobs = -1, verbose = 2, scoring = \"roc_auc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iazWY1vMi6iK"
      },
      "source": [
        "# use sub-sample since took too long to train\n",
        "subsample = stopwords_lemmatize.sample(n=10000, random_state = 3244)\n",
        "X = subsample[[\"cosine_similarity\", \"common_words_count\", \"Partial_Ratio\"]]\n",
        "y = subsample[[\"is_duplicate\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywzhNxfGi4aD"
      },
      "source": [
        "subsample.head()\n",
        "subsample[\"is_duplicate\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wki_t-L2i4b7"
      },
      "source": [
        "# Fit grid search to data\n",
        "grid_search.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LizgL5m2jLSI"
      },
      "source": [
        "best_grid = grid_search.best_params_\n",
        "best_grid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgjai8ZFjLVU"
      },
      "source": [
        "# Create model with parameters found\n",
        "model_grid = xgb.XGBClassifier(objective = 'binary:logistic',\n",
        "                               silen = True, nthread = 1, **best_grid)\n",
        "fprs, tprs, scores = [], [], []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_zbyrsyjMmM"
      },
      "source": [
        "!pip install shap\n",
        "import shap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXDHAP4ljMoA"
      },
      "source": [
        "# Feature importance plot\n",
        "fig, ax = plt.subplots(figsize=(15,20))\n",
        "xgb.plot_importance(model_grid, ax=ax)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJpLh9PjQD0"
      },
      "source": [
        "# SHAP\n",
        "explainer = shap.TreeExplainer(model_grid)\n",
        "shap_values = explainer.shap_values(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehppPpx1jQFo"
      },
      "source": [
        "shap.summary_plot(shap_values, X_test, plot_type='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65Adk4Uat2KK"
      },
      "source": [
        "# perform LIME"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5FB3Rfbt2MK"
      },
      "source": [
        "train_cleaned_features[train_cleaned_features.index == 298805]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-903G3rut2OG"
      },
      "source": [
        "test.iloc[[421]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLCN-Pftt6tq"
      },
      "source": [
        "choosen_instance = X_test.iloc[[421]].values[0]\n",
        "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=10)\n",
        "exp.show_in_notebook(show_all=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzuUf6AMt6vf"
      },
      "source": [
        "train_cleaned_features[train_cleaned_features.index == 21066]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQZOY2Bot9KK"
      },
      "source": [
        "test.iloc[[281]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1ObWJL3t96w"
      },
      "source": [
        "choosen_instance = X_test.iloc[[281]].values[0]\n",
        "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=10)\n",
        "exp.show_in_notebook(show_all=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}